{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 121,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import uuid\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sqlalchemy import create_engine, text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Configuración de la conexión a la base de datos\n",
    "def create_db_connection():\n",
    "    return create_engine('postgresql://postgres:developer@localhost:5434/pipeline')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Función para obtener todos los archivos CSV en un directorio, excluyendo el de validación\n",
    "def get_csv_files(directory):\n",
    "    return sorted([os.path.join(directory, f) for f in os.listdir(directory) if f.endswith('.csv') and 'validation' not in f])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generar un identificador único de lote usando UUID\n",
    "def generate_batch_uuid():\n",
    "    return str(uuid.uuid4())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Inicialización de las estadísticas\n",
    "def init_stats():\n",
    "    return {'count': 0, 'sum_price': 0, 'min_price': np.inf, 'max_price': -np.inf, 'avg_price': 0}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Actualización de las estadísticas\n",
    "def update_stats_buffer_memory(stats, new_data):\n",
    "    stats['count'] += len(new_data)\n",
    "    stats['sum_price'] += new_data['price'].sum()\n",
    "    stats['min_price'] = min(stats['min_price'], new_data['price'].min())\n",
    "    stats['max_price'] = max(stats['max_price'], new_data['price'].max())\n",
    "    if stats['count'] > 0:\n",
    "        stats['avg_price'] = stats['sum_price'] / stats['count']\n",
    "    else:\n",
    "        stats['avg_price'] = 0\n",
    "    return stats"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cargar datos, añadir columna de origen y actualizar estadísticas\n",
    "def load_data_and_update_stats(file_name, engine, stats, batch_uuid):\n",
    "    data = pd.read_csv(file_name)\n",
    "    data['source_file'] = os.path.basename(file_name)\n",
    "    data['batch_uuid'] = batch_uuid\n",
    "    file_size = os.path.getsize(file_name)\n",
    "    data['file_size'] = file_size\n",
    "    data.to_sql('transaction_data', con=engine, if_exists='append', index=False)\n",
    "    stats = update_stats_buffer_memory(stats, data)\n",
    "    print(f\"Loaded {file_name} with file size {file_size} bytes and batch hash {batch_uuid}, updated stats\")\n",
    "    return stats"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Consultar estadísticas de la base de datos\n",
    "def query_stats_sql(engine):\n",
    "    query = text(\"\"\"\n",
    "        SELECT COUNT(*) AS total_count,\n",
    "               AVG(price) AS avg_price,\n",
    "               MIN(price) AS min_price,\n",
    "               MAX(price) AS max_price\n",
    "        FROM transaction_data\n",
    "    \"\"\")\n",
    "    with engine.connect() as conn:\n",
    "        result = conn.execute(query)\n",
    "        stats = result.fetchone()\n",
    "        return {\n",
    "            'total_count': stats[0],\n",
    "            'avg_price': float(stats[1]),\n",
    "            'min_price': float(stats[2]),\n",
    "            'max_price': float(stats[3])\n",
    "        }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Función principal para procesar los archivos y realizar comprobaciones\n",
    "def process_files_and_validate(directory, validation_file):\n",
    "    engine = create_db_connection()\n",
    "    stats = init_stats()\n",
    "    batch_uuid = generate_batch_uuid()\n",
    "    \n",
    "    # Procesar todos los archivos excepto el de validación\n",
    "    csv_files = get_csv_files(directory)\n",
    "    for file in csv_files:\n",
    "        stats = load_data_and_update_stats(file, engine, stats, batch_uuid)\n",
    "        print(\"Current in-memory stats:\", stats)\n",
    "    \n",
    "    # Procesar el archivo de validación\n",
    "    print(\"\\nProcessing validation file...\")\n",
    "    validation_stats = load_data_and_update_stats(validation_file, engine, stats, batch_uuid)\n",
    "    print(\"Validation file stats:\", validation_stats)\n",
    "    \n",
    "    # Consulta final para ver cómo cambiaron los valores después de cargar validation.csv\n",
    "    final_db_stats = query_stats_sql(engine)\n",
    "    print(\"Final database stats after loading validation.csv:\", final_db_stats)\n",
    "\n",
    "    return stats, validation_stats, final_db_stats"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Directorio donde se encuentran tus archivos CSV y nombre del archivo de validación\n",
    "directory = '../input'\n",
    "validation_file = '../input/validation.csv'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded ../input/2012-1.csv with file size 374 bytes and batch hash 691d2178-0c7a-46d6-a425-ad228c2ccf96, updated stats\n",
      "Current in-memory stats: {'count': 22, 'sum_price': 1193.0, 'min_price': 14.0, 'max_price': 97.0, 'avg_price': 54.22727272727273}\n",
      "Loaded ../input/2012-2.csv with file size 482 bytes and batch hash 691d2178-0c7a-46d6-a425-ad228c2ccf96, updated stats\n",
      "Current in-memory stats: {'count': 51, 'sum_price': 2783.0, 'min_price': 10, 'max_price': 100, 'avg_price': 54.568627450980394}\n",
      "Loaded ../input/2012-3.csv with file size 513 bytes and batch hash 691d2178-0c7a-46d6-a425-ad228c2ccf96, updated stats\n",
      "Current in-memory stats: {'count': 82, 'sum_price': 4633.0, 'min_price': 10, 'max_price': 100, 'avg_price': 56.5}\n",
      "Loaded ../input/2012-4.csv with file size 495 bytes and batch hash 691d2178-0c7a-46d6-a425-ad228c2ccf96, updated stats\n",
      "Current in-memory stats: {'count': 112, 'sum_price': 6240.0, 'min_price': 10, 'max_price': 100, 'avg_price': 55.714285714285715}\n",
      "Loaded ../input/2012-5.csv with file size 513 bytes and batch hash 691d2178-0c7a-46d6-a425-ad228c2ccf96, updated stats\n",
      "Current in-memory stats: {'count': 143, 'sum_price': 8046.0, 'min_price': 10, 'max_price': 100, 'avg_price': 56.26573426573427}\n",
      "\n",
      "Processing validation file...\n",
      "Loaded ../input/validation.csv with file size 145 bytes and batch hash 691d2178-0c7a-46d6-a425-ad228c2ccf96, updated stats\n",
      "Validation file stats: {'count': 151, 'sum_price': 8380.0, 'min_price': 10, 'max_price': 100, 'avg_price': 55.496688741721854}\n",
      "Final database stats after loading validation.csv: {'total_count': 302, 'avg_price': 57.006802721088434, 'min_price': 10.0, 'max_price': 100.0}\n"
     ]
    }
   ],
   "source": [
    "# Ejecución del pipeline\n",
    "final_stats, validation_stats, final_db_stats = process_files_and_validate(directory, validation_file)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "lab_2",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
